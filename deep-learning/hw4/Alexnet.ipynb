{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    ".....IMPORTANT USAGE INSTRUCTIONS........\n",
    "\n",
    "    IF USING CHPC - UTAH\n",
    "\n",
    "        Download this Jupyter Notebook to a local location on your Computer\n",
    "\n",
    "        Go to https://ondemand.chpc.utah.edu and sign in using your uNID and Password.\n",
    "\n",
    "        At the Top of the Page, notice the Menu \"Interactive Apps\". Click and Choose \"Jupyter Notebook on Notchpeak\"\n",
    "\n",
    "        A form will open, enter all details, and then Launch a Jupyter Notebook. It will take a minute.\n",
    "\n",
    "        Click on \"Connect to Jupyter\"\n",
    "\n",
    "        Once Jupyter Launches. On Top Right Notice \"Upload Button\". Use this to Upload this Notebook.\n",
    "\n",
    "        The Notebook will be uploaded. Finish writing the Code whereever specified.\n",
    "\n",
    "        Run each Block of Code and then finally download the Jupyter Notebook by going to File >> Download as >>\n",
    "\n",
    "\n",
    "    IF USING GOOGLE COLAB\n",
    "\n",
    "        Download this Jupyter Notebook to a local location on your Computer\n",
    "\n",
    "        Go to https://colab.research.google.com/ and sign in using your Google Account - So that your work is saved \n",
    "        in your Google Drive permanently.\n",
    "\n",
    "        Go to File >> Upload Notebook.\n",
    "\n",
    "        Finish writing the Code whereever specified.\n",
    "\n",
    "        Run each Block of Code ad then finally download the Jupyter Notebook by going to File >> Download .ipynb\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    ".....IMPORTANT SUBMISSION INSTRUCTIONS........\n",
    "\n",
    "Once everything runs successfully, download the jupyter notebook and attach that to your submission in Canvas. \n",
    "During evaluation, I will run your Jupyter Notebook to verify that everything is running as expected.\n",
    "\n",
    "Do not forget to include your main results and plots in your latex file (with other homework questions) \n",
    "before submission.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import json, string\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Alexnet by default is pretrained on imagenet dataset with 1000 classes. Therefore to use Alexnet out of the box \n",
    "on any image, we first need to import description of the imagenet classes. A textfile with all imagenet classes\n",
    "are provided. We will import it as it is.\n",
    "\n",
    "'''\n",
    "\n",
    "with open('imagenet_classes.txt') as f:\n",
    "  labels = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Step - 1 : Download the pretrained Alexnet\n",
    "'''\n",
    "\n",
    "alexnet = models.alexnet(pretrained = True)\n",
    "\n",
    "\n",
    "'''\n",
    "Optional - Print out the structure of Alexnet\n",
    "'''\n",
    "\n",
    "#print(alexnet)\n",
    "\n",
    "\n",
    "'''\n",
    "Step - 2 : Always a good practice to preprocess the images(s)\n",
    "'''\n",
    "\n",
    "preprocessFn = transforms.Compose([transforms.Scale(256),\n",
    "                                   transforms.CenterCrop(224),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                                        std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "'''\n",
    "Step - 3 : Instantiate Alexnet in Eval Mode\n",
    "'''\n",
    "\n",
    "alexnet.eval()\n",
    "\n",
    "'''\n",
    "Step - 4 : Load a Test Image and Preprocess \n",
    "'''\n",
    "path = ...\n",
    "image = Image.open(path).convert('RGB')\n",
    "inputVar =  Variable(preprocessFn(image).unsqueeze(0))\n",
    "\n",
    "\n",
    "'''\n",
    "Step - 5 : Run the Image through Alexnet\n",
    "'''\n",
    "predictions = ...\n",
    "print(predictions.shape)\n",
    "\n",
    "'''\n",
    "Step - 6 : Output the Top Probability\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "Step - 7 : Out the Image with Label and Probability\n",
    "'''\n",
    "\n",
    "plt.title(labels[predictions.argmax().item()] + '     ,Probability = ' + str(probs[0]))\n",
    "plt.imshow(image);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to extract 1st Layer from Alexnet and Display shape\n",
    "\n",
    "'''\n",
    "Import the image and preprocess\n",
    "'''\n",
    "\n",
    "path = ...\n",
    "image_c = Image.open(path).convert('RGB')\n",
    "iVar =  Variable(preprocessFn(image_c).unsqueeze(0))\n",
    "\n",
    "'''\n",
    "Extract the first Convolutional Layer\n",
    "'''\n",
    "feature_extraction = [child for child in alexnet.children()][0]\n",
    "convolution_layer = feature_extraction[0]\n",
    "\n",
    "'''\n",
    "Run the image through this convolutional layer. Print out the shape and also the image representation.\n",
    "'''\n",
    "out = convolution_layer.forward(iVar)\n",
    "print(out[0][0].shape)\n",
    "\n",
    "'''\n",
    "Note - The first Convolutional Layer extracts the outlines of the figure.\n",
    "'''\n",
    "plt.imshow(out[0][0].detach().numpy())\n",
    "\n",
    "'''\n",
    "*********\n",
    "Write the code that outputs a grid (8x8) of the 64 images you get as the output of the first convolutional layer\n",
    "*******\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now visualize the filters\n",
    "* Look how I am extracting the weights of the 51th filter of the first channel \n",
    "and just extend it to create a grid plot of the 64 filters \n",
    "'''\n",
    "\n",
    "plt.imshow(alexnet.features[0].weight.data[50,0,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here you will feed to the network your own image. And output the top 5 probabilities of the predicted classes.\n",
    "* Make sure you make some preprocessing to it, you can also try blurring the image and see what happens\n",
    "* Make sure your image class corresponds to one of the 1000 classes of alexnet\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d34b9460366b78c854f620c66445fee9afeecf972eedca0a7e75b88f83987c10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
